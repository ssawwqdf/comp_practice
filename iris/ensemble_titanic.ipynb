{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2536e530-02e8-4a30-a3f1-39ad9efcceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 경고\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# 날짜 가공\n",
    "import datetime as dt \n",
    "from dateutil.rrule import rrule, YEARLY, MONTHLY, WEEKLY\n",
    "\n",
    "# 데이터 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='Gothic') # For Windows. PLOT에서 한글 처리 -> 플롯 만드는 창에 넣어야 됨.\n",
    "\n",
    "plt.rcParams['font.family']= 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False # - 기호 안 깨지게\n",
    "plt.rcParams['font.size'] = 15\n",
    "# plt.figure(figsize=(12,4)) # plot 12:4 비율\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set() # seaborn에서 회색 grid 깔아줌\n",
    "sns.set(rc={'figure.figsize':(18, 5)}) # 결과 plot 크기 키워줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b84cc66d-87e5-450f-b6d3-b8eccb10207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30091f8b-4628-4ca8-a25e-b08fd4dc07ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 점수\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\t\t\t\t\t\t # ---> y_true, y_pred\n",
    "from sklearn.metrics import precision_recall_curve # y_true, probas_pred\n",
    "from sklearn.metrics import roc_auc_score, roc_curve # y_true, y_score\n",
    "\n",
    "# 사이킷런 스케일러\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "\n",
    "# 사이킷런 학습 데이터 증강\n",
    "# StratifiedFold는 회귀에서는 X\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b347e5e-2bca-4917-ba97-a3d243bf431c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03639e97-ee53-4b86-b1c5-a0b4a9cd2f18",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "082e12de-5762-41a1-b8c2-d01a38091531",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=pd.read_csv(\"./dataset/gg_titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c27a6f0-8e76-4126-b093-5b8f47fe61bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Name_title</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Fare_binning</th>\n",
       "      <th>Age_binning</th>\n",
       "      <th>family_binning</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Cabin  Embarked  Name_title  Sex  Fare_binning  Age_binning  \\\n",
       "0       3      0         1           3    1             1            3   \n",
       "1       1      3         2           4    0             4            6   \n",
       "2       3      0         1           2    0             2            4   \n",
       "3       1      3         1           4    0             4            6   \n",
       "4       3      0         1           3    1             2            6   \n",
       "\n",
       "   family_binning  Survived  \n",
       "0               2         0  \n",
       "1               2         1  \n",
       "2               1         1  \n",
       "3               2         1  \n",
       "4               1         0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c305e33-9f38-445d-9258-81933a56c99a",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66383899-35b2-410a-bc47-f400f6fb4484",
   "metadata": {},
   "source": [
    "# Check score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51c2c151-2cee-426d-9efa-61ce4230d13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=iris.drop('Survived', axis=1)\n",
    "y=iris['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fa3295b-7bf1-47cc-979a-e56b5c5698d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1024, test_size=0.2) # test_size 조정 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea2a3ff7-fac4-4ee5-9f89-020b2238fc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 8) (179, 8) (712,) (179,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93ccd1b4-0a5c-4b14-8b4d-043c50ddfae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.8218 accuracy: 0.8380\n",
      "[[102  10]\n",
      " [ 19  48]]\n"
     ]
    }
   ],
   "source": [
    "model=RandomForestClassifier(n_estimators=100, random_state=1024)\n",
    "model.fit(X_train, y_train)\n",
    "pred=model.predict(X_test)\n",
    "f1=f1_score(y_test, pred, average='macro')\n",
    "acc=accuracy_score(y_test, pred)\n",
    "print(f\"f1: {f1:.4f} accuracy: {acc:.4f}\")\n",
    "cm=confusion_matrix(y_test, pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9caf0cb4-6e92-4c3a-ac14-5a27dbb832d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_fitscore(name):\n",
    "    model.fit(X_train, y_train)\n",
    "    pred=model.predict(X_test)\n",
    "    \n",
    "    acc=accuracy_score(y_test, pred)\n",
    "    f1=f1_score(y_test, pred, average='macro')\n",
    "    \n",
    "    print(f\"accuracy: {acc:.4f}  f1: {f1:.4f}\")\n",
    "    \n",
    "    cm=confusion_matrix(y_test, pred)\n",
    "    print(cm)\n",
    "    \n",
    "    return name, acc, f1 # 클래스 모델이름 없는 애들도 있어서 이거 뺌model.__class__.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c795ffb9-b54f-4fee-a645-e4785ca233a7",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3229f76a-69bb-4490-acf8-7b79693e0ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb39eb7c-eda2-48da-9c4e-3a24d0124c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9fbf42-637d-446e-bd0f-40881bb22c46",
   "metadata": {
    "tags": []
   },
   "source": [
    "## XGBoost Wrpper- python (원형 문법)\n",
    "<pre>\n",
    "import xgboost as xgb\n",
    "# read in data\n",
    "dtrain = xgb.DMatrix('demo/data/agaricus.txt.train')\n",
    "dtest = xgb.DMatrix('demo/data/agaricus.txt.test')\n",
    "# specify parameters via map\n",
    "param = {'max_depth':2, 'eta':1, 'objective':'binary:logistic' }\n",
    "num_round = 2\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "# make prediction\n",
    "preds = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5d843bf-8727-4ef4-84c3-033447b74c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "# tree모델이라 fearture importance 준다. 얘는 예전이랑 다르게 지가 일아서 데이터프레임 만들고 돌려서 그려줌\n",
    "from xgboost import plot_importance # 그걸 해주는 게 얘임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f0ab324-e2cc-4895-b337-a3826f78897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 자체의 에러\n",
    "\n",
    "# read in data\n",
    "# dm_train = xgb.DMatrix(data=X_train, label=y_train)\n",
    "# dm_test = xgb.DMatrix(data=X_test, label=y_test)\n",
    "# # specify parameters via map                                                      \n",
    "# my_param = {'max_depth':5,\n",
    "#             'eta':0.1,\n",
    "#             # 'objective':'binary:logistic', # 0,1\n",
    "#             'objective':'multi:softmax',  # 1,2,3 # ---------- bug!!!!\n",
    "#             # 'objective':'multi:softprob', # 0.2, 0.3, 0.5\n",
    "#             'eval_metric': 'auc',        # mlogloss쓸 수도 있다.\n",
    "#             'early_stopping': 100 }\n",
    "# # num_boost_round = 10\n",
    "# train_object = xgb.train(my_param, dm_train, num_boost_round=10)\n",
    "# # make prediction\n",
    "# pred = train_object.predict(dm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "501ca4b2-ade8-4eed-a4a6-e8c428bc08a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런으로 쓸 거라 패스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ac6f71-4dd6-47d1-a957-1a4abfe8163b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "339969ea-dc29-441b-a09c-63c34aff983e",
   "metadata": {},
   "source": [
    "## XGBoost Wrapper - sklearn (조금 다른 문법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a7d11fc-40ad-4215-91cf-fc74fbe13a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier # class -> XGBModel을 상속받음\n",
    "# xgb=XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64b9ffbe-a150-4a2f-a20c-aa46ada62e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:36:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "f1: 0.8163 accuracy: 0.8324\n",
      "[[101  11]\n",
      " [ 19  48]]\n"
     ]
    }
   ],
   "source": [
    "# 사이킷런에서 model -> xgb로 설정한 거라 생각하면 됨\n",
    "xgb=XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=1024)\n",
    "xgb.fit(X_train, y_train)\n",
    "pred=xgb.predict(X_test)\n",
    "f1=f1_score(y_test, pred, average='macro')\n",
    "acc=accuracy_score(y_test, pred)\n",
    "print(f\"f1: {f1:.4f} accuracy: {acc:.4f}\")\n",
    "cm=confusion_matrix(y_test, pred)\n",
    "print(cm)\n",
    "\n",
    "# 왜 나는 똑같냐..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53992f5-5fa4-4049-8bdf-bb37a0d3238c",
   "metadata": {},
   "source": [
    "# Lightgbm  \n",
    "https://github.com/microsoft/LightGBM/blob/master/examples/python-guide/sklearn_example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b848f05-4cdc-4981-911b-8a97d757a7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "# lgb.LGBMClassifier\n",
    "\n",
    "# lgb.쓰기 귀찮으니까 Classifier까지 import\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a75cf8e-f2e8-4f87-9217-af4ef6d37edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.8041 accuracy: 0.8212\n",
      "[[100  12]\n",
      " [ 20  47]]\n"
     ]
    }
   ],
   "source": [
    "# 규제 필요하면 GBoost 쓰고 속도 필요하면 lightgbm 쓰면 된다.\n",
    "\n",
    "model=LGBMClassifier(max_depth=5, learning_rate=0.1, n_estimators=100, random_state=1024)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train) #, eval_set=[(X_test, y_test)] # 점수도 내부에서 설정 가능\n",
    "pred=model.predict(X_test)\n",
    "\n",
    "f1=f1_score(y_test, pred, average='macro')\n",
    "acc=accuracy_score(y_test, pred)\n",
    "\n",
    "print(f\"f1: {f1:.4f} accuracy: {acc:.4f}\")\n",
    "\n",
    "cm=confusion_matrix(y_test, pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efc35a9-bfe1-45c5-b56a-ed40bd8313cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "462e1119-1507-4c87-beca-4c9a00e12e43",
   "metadata": {},
   "source": [
    "# ensemble Votting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0a8b3e8-6681-4d3b-a02b-657e6437265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "# vmodel=VotingClassifier([(str,model),... ], voting=\"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe80c742-413c-42ff-8ac9-74a13ce0c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=VotingClassifier([('rf',RandomForestClassifier()),('lr', LogisticRegression()) ], voting=\"hard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a582c696-9801-4dee-8792-6ce54e8670f1",
   "metadata": {},
   "source": [
    "# ensemble.BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8851669c-d98d-4efa-a816-e6a4f8bbdd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9105333-e376-4d42-9dde-d846229a5df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=RandomForestClassifier(n_estimators=100, random_state=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09ffed9c-c8c5-494c-a1c4-9c7f122e2e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4c8665d-b4ef-43ee-806a-e2bfa64e127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=LGBMClassifier(max_depth=5, learning_rate=0.1, n_estimators=100, random_state=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "329155c5-39e6-417d-bdec-86e2be8d3151",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4=VotingClassifier([('rf',RandomForestClassifier()),('lr', LogisticRegression()) ], voting=\"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d08143e-b723-4c62-b01f-012d350261fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5=BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                  n_estimators=10, max_samples=1.0,\n",
    "                  max_features=1.0, bootstrap=True,\n",
    "                  oob_score=False, random_state=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "411ef0bd-75b2-45d6-826a-321899f97afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "    dt    \n",
      "----------------------------------------\n",
      "accuracy: 0.7933  f1: 0.7690\n",
      "[[100  12]\n",
      " [ 25  42]]\n",
      "----------------------------------------\n",
      "    rf    \n",
      "----------------------------------------\n",
      "accuracy: 0.8380  f1: 0.8218\n",
      "[[102  10]\n",
      " [ 19  48]]\n",
      "[23:36:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "----------------------------------------\n",
      "    xgboost    \n",
      "----------------------------------------\n",
      "accuracy: 0.8324  f1: 0.8163\n",
      "[[101  11]\n",
      " [ 19  48]]\n",
      "----------------------------------------\n",
      "    lgbm    \n",
      "----------------------------------------\n",
      "accuracy: 0.8045  f1: 0.7715\n",
      "[[106   6]\n",
      " [ 29  38]]\n",
      "----------------------------------------\n",
      "    voting    \n",
      "----------------------------------------\n",
      "accuracy: 0.7933  f1: 0.7608\n",
      "[[104   8]\n",
      " [ 29  38]]\n",
      "----------------------------------------\n",
      "    bagging    \n",
      "----------------------------------------\n",
      "accuracy: 0.7598  f1: 0.7316\n",
      "[[97 15]\n",
      " [28 39]]\n"
     ]
    }
   ],
   "source": [
    "                    # 기본모델              #-------앙상블\n",
    "model_list=[('dt',DecisionTreeClassifier()),('rf',model1),('xgboost',model2),('lgbm',model4),('voting',model4),('bagging',model5)]\n",
    "for tupl in model_list:\n",
    "    model_name=tupl[0]\n",
    "    model=tupl[1]\n",
    "    # --------점수 내기\n",
    "    model.fit(X_train, y_train)\n",
    "    pred=model.predict(X_test)\n",
    "    \n",
    "    # ----------\n",
    "    print(\"--\"*20)\n",
    "    print(f\"    {model_name}    \")\n",
    "    print(\"--\"*20)\n",
    "    ###\n",
    "    acc=accuracy_score(y_test, pred)\n",
    "    f1=f1_score(y_test, pred, average='macro')\n",
    "    \n",
    "    print(f\"accuracy: {acc:.4f}  f1: {f1:.4f}\")\n",
    "    \n",
    "    cm=confusion_matrix(y_test, pred)\n",
    "    print(cm)\n",
    "    \n",
    "    # return name, acc, f1 # 클래스 모델이름 없는 애들도 있어서 이거 뺌 model.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5089a09-cb84-4867-8566-720ad7f49764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:36:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "list1=[]\n",
    "list2=[]\n",
    "list3=[]\n",
    "\n",
    "                    # 기본모델              #-------앙상블\n",
    "model_list=[('dt',DecisionTreeClassifier()),('rf',model1),('xgboost',model2),('lgbm',model4),('voting',model4),('bagging',model5)]\n",
    "for tupl in model_list:\n",
    "    model_name=tupl[0]\n",
    "    model=tupl[1]\n",
    "    # --------점수 내기\n",
    "    model.fit(X_train, y_train)\n",
    "    pred=model.predict(X_test)\n",
    "    \n",
    "    # ----------\n",
    "    # print(\"--\"*20)\n",
    "    # print(f\"    {model_name}    \")\n",
    "    # print(\"--\"*20)\n",
    "    ###\n",
    "    acc=accuracy_score(y_test, pred)\n",
    "    f1=f1_score(y_test, pred, average='macro')\n",
    "    \n",
    "    # print(f\"accuracy: {acc:.4f}  f1: {f1:.4f}\")\n",
    "    \n",
    "    cm=confusion_matrix(y_test, pred)\n",
    "    # print(cm)\n",
    "    \n",
    "    list1.append(model_name)\n",
    "    list2.append(acc)\n",
    "    list3.append(f1)\n",
    "    \n",
    "    # return name, acc, f1 # 클래스 모델이름 없는 애들도 있어서 이거 뺌 model.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db2693c3-3fe1-4b05-bf09-6ab15e992557",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df=pd.DataFrame({\"model\":list1, \"acc\":list2, \"f1\":list3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "310d4343-51ee-4a26-9d70-1fd7612417f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dt</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.761835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.821768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.816297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.763783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>voting</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.753121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model       acc        f1\n",
       "0       dt  0.787709  0.761835\n",
       "1       rf  0.837989  0.821768\n",
       "2  xgboost  0.832402  0.816297\n",
       "3     lgbm  0.798883  0.763783\n",
       "4   voting  0.787709  0.753121"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c45b397-90bc-428d-8192-2fb6dbb33940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터가 작아서 별 차이는 없다 ^^;;;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ccff9-5a74-45f0-8365-a655daa96796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a65e3b4-ca84-44b5-87e8-f10eca378d07",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "746b0be7-4f78-479c-a437-b2fbe1723363",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "lg = LogisticRegression()\n",
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76e8a40f-392c-4df3-8b48-ce786863b741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 8) (179, 8) (712,) (179,)\n"
     ]
    }
   ],
   "source": [
    "X=iris.drop('Survived', axis=1)\n",
    "y=iris['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1024, test_size=0.2) # test_size 조정 가능\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f33a1383-934a-4445-afe4-31a4178f035c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 1)\n"
     ]
    }
   ],
   "source": [
    "rf_yellow=np.zeros(shape=(X_train.shape[0], 1))\n",
    "lg_yellow=np.zeros(shape=(X_train.shape[0], 1))\n",
    "dt_yellow=np.zeros(shape=(X_train.shape[0], 1))\n",
    "print(rf_yellow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8599ddca-3f69-4681-b771-393b41794b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179, 5)\n"
     ]
    }
   ],
   "source": [
    "# 여기서 5는 cv 다섯 번 돌려서 5열인 것\n",
    "rf_green=np.zeros(shape=(X_test.shape[0], 5))\n",
    "lg_green=np.zeros(shape=(X_test.shape[0], 5))\n",
    "dt_green=np.zeros(shape=(X_test.shape[0], 5))\n",
    "print(rf_green.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c9300c09-d2e7-4a35-a52f-14c68fc9aead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 3) (179, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "sk = StratifiedKFold(n_splits=5, shuffle=True, random_state=1024)\n",
    "\n",
    "for i, (train_idx, validation_idx) in enumerate(sk.split(X_train, y_train)): # 원래는 X, y 전체 넣었었는데 지금은 이미 찢은 상황이라\n",
    "    X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    X_validation_fold, y_validation_fold = X_train.iloc[validation_idx], y_train.iloc[validation_idx]\n",
    "    \n",
    "    rf.fit(X_train_fold, y_train_fold)\n",
    "    lg.fit(X_train_fold, y_train_fold)\n",
    "    dt.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    rf_pred=rf.predict(X_validation_fold) # 가로줄로 나온다.\n",
    "    lg_pred=lg.predict(X_validation_fold)\n",
    "    dt_pred=dt.predict(X_validation_fold)\n",
    "    \n",
    "    rf_yellow[validation_idx, :]=rf_pred.reshape(-1,1)\n",
    "    lg_yellow[validation_idx, :]=lg_pred.reshape(-1,1)\n",
    "    dt_yellow[validation_idx, :]=dt_pred.reshape(-1,1)\n",
    "    \n",
    "    # 이 노란 박스 세 개 합치면 합쳐진 노란박스가 된 것\n",
    "    \n",
    "    # -------------------test------------------------------\n",
    "    rf_pred=rf.predict(X_test)\n",
    "    lg_pred=lg.predict(X_test)\n",
    "    dt_pred=dt.predict(X_test)\n",
    "    \n",
    "    rf_green[:,i]=rf_pred #.reshape(-1,1)\n",
    "    lg_green[:,i]=lg_pred #.reshape(-1,1)\n",
    "    dt_green[:,i]=dt_pred #.reshape(-1,1)\n",
    "    \n",
    "rf_green_mean=np.mean(rf_green,axis=1).reshape(-1,1)\n",
    "lg_green_mean=np.mean(lg_green,axis=1).reshape(-1,1)\n",
    "dt_green_mean=np.mean(dt_green,axis=1).reshape(-1,1)\n",
    "\n",
    "new_train=np.concatenate([rf_yellow, lg_yellow, dt_yellow], axis=1)\n",
    "\n",
    "new_test=np.concatenate([rf_green_mean, lg_green_mean, dt_green_mean], axis=1)\n",
    "print(new_train.shape, new_test.shape) # 빨간 박스\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3833a924-02f1-4fc8-807f-2a6c76330398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:0.7899 accuracy:0.7989\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "model = LGBMClassifier(max_depth=5, learning_rate=0.1, n_estimators=100, random_state=1234)        \n",
    "model.fit(new_train, y_train)   # , eval_set=[(X_test, y_test)]        \n",
    "pred = model.predict(new_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "f1 = f1_score(y_test, pred, average='macro')\n",
    "print(f\"f1:{f1:.4f} accuracy:{accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dddb2667-2a1c-4cce-9363-07d935db7d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stacking: StackingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5fef3adb-c9cb-4dd0-97d0-96e9162d4f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 1 features, but RandomForestClassifier is expecting 3 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12360/651118432.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myellow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgreen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ai\\pythonproject\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    806\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m         \"\"\"\n\u001b[1;32m--> 808\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ai\\pythonproject\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    848\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 850\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ai\\pythonproject\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    577\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[0;32m    578\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ai\\pythonproject\\venv\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ai\\pythonproject\\venv\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    401\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[1;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 1 features, but RandomForestClassifier is expecting 3 features as input."
     ]
    }
   ],
   "source": [
    "# # 백지 타이핑 연습 ********************************************\n",
    "\n",
    "# # 주요 틀린 것\n",
    "# # rf_green 등 만들 때는 reshape 안 해도 된다\n",
    "# # mean은 cv로 만들어진 거에 대해서 한다.\n",
    "# # 결론적으로 만들어진 new_train과 new_test는 돌린 모델의 개수만큼 열을 갖는다.\n",
    "# # axis 방향 계속 헷갈림\n",
    "\n",
    "# # X_train, X_test, y_train, y_test\n",
    "\n",
    "# X=iris.drop('Survived',axis=1)\n",
    "# y=iris['Survived']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1024)\n",
    "\n",
    "# sk = StratifiedKFold(n_splits=5, shuffle=True, random_state=1024)\n",
    "# rf=RandomForestClassifier(n_estimators=100, random_state=1024)\n",
    "# lg=LogisticRegression()\n",
    "# dt=DecisionTreeClassifier()\n",
    "\n",
    "# # yellow=np.zeros(shape=(X_train.shape[0] ,3))\n",
    "# # green=np.zeros(shape=(X_test.shape[0] ,5))\n",
    "\n",
    "# rf_yellow=np.zeros(shape=(X_train.shape[0], 1))\n",
    "# lg_yellow=np.zeros(shape=(X_train.shape[0], 1))\n",
    "# dt_yellow=np.zeros(shape=(X_train.shape[0], 1))\n",
    "\n",
    "# # 여기서 5는 cv 다섯 번 돌려서 5열인 것\n",
    "# rf_green=np.zeros(shape=(X_test.shape[0], 5))\n",
    "# lg_green=np.zeros(shape=(X_test.shape[0], 5))\n",
    "# dt_green=np.zeros(shape=(X_test.shape[0], 5))\n",
    "\n",
    "# for i, (idx, val_index) in enumerate(sk.split(X_train, y_train)):\n",
    "    \n",
    "#     #---- split train into fold_train & fold_validation ----\n",
    "    \n",
    "#     X_fold_train=X_train.iloc[idx, :]      # stratified -> train용 X\n",
    "#     X_fold_val=X_train.iloc[val_index,:]  # stratified -> test용 X\n",
    "#     y_fold_train=y_train.iloc[idx]      # stratified -> train용 y\n",
    "#     y_fold_val=y_train.iloc[val_index]  # stratified -> test용 y\n",
    "    \n",
    "#     #--------- fold_train & fold_validation에 대해 ---------\n",
    "    \n",
    "#     rf.fit(X_fold_train, y_fold_train)\n",
    "#     lr.fit(X_fold_train, y_fold_train)\n",
    "#     dt.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "#     rf_pred=rf.predict(X_fold_val).reshape(-1,1)\n",
    "#     lg_pred=lr.predict(X_fold_val).reshape(-1,1)\n",
    "#     dt_pred=dt.predict(X_fold_val).reshape(-1,1)\n",
    "\n",
    "#     rf_yellow[val_index,:]=rf_pred\n",
    "#     lg_yellow[val_index,:]=lg_pred\n",
    "#     dt_yellow[val_index,:]=dt_pred\n",
    "    \n",
    "#     #--------------------test에 대해------------------------\n",
    "    \n",
    "#     rf.fit(X_test, y_test)\n",
    "#     lr.fit(X_test, y_test)\n",
    "#     dt.fit(X_test, y_test)\n",
    "    \n",
    "#     rf_pred=rf.predict(X_test)\n",
    "#     lr_pred=lr.predict(X_test)\n",
    "#     dt_pred=dt.predict(X_test)\n",
    "    \n",
    "#     rf_green[:,i]=rf_pred\n",
    "#     lg_green[:,i]=lr_pred\n",
    "#     dt_green[:,i]=dt_pred\n",
    "    \n",
    "\n",
    "# #     rf_pred=rf.predict(X_test).reshape(-1,1)\n",
    "# #     lr_pred=lr.predict(X_test).reshape(-1,1)\n",
    "# #     dt_pred=dt.predict(X_test).reshape(-1,1)\n",
    "    \n",
    "# #     rf_green[:,i]=rf_pred           # -----------에러 : reshape했기때문 / 왤까?\n",
    "# #     lg_green[:,i]=lr_pred\n",
    "# #     dt_green[:,i]=dt_pred\n",
    "\n",
    "#     # rf_green[:,i]=rf.predict(X_test) # 왜 얘는 reshape 안 해도 될까??\n",
    "#     # lg_green[:,i]=lr.predict(X_test)\n",
    "#     # dt_green[:,i]=dt.predict(X_test)\n",
    "\n",
    "    \n",
    "# new_train=np.concatenate([rf_yellow,lg_yellow,dt_yellow], axis=1)\n",
    "# new_test=np.mean([rf_green, lg_green, dt_green], axis=0) # 0이다!! /// error!!!!!! 각 mean은 따로 만들어야 됨\n",
    "        \n",
    "# green=np.mean(green, axis=1).reshape(-1,1)\n",
    "    \n",
    "# print(green.shape)\n",
    "\n",
    "# model=RandomForestClassifier(n_estimators=100, random_state=1024)\n",
    "# model.fit(yellow, y_train)\n",
    "# pred=model.predict(green)\n",
    "# f1=f1_score(y_test, pred)\n",
    "# print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b64b67aa-ce99-4343-bb61-32f0edabacc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 백지타이핑 연습용\n",
    "# print(yellow.shape, green.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "49a8ae6f-c096-427a-b90a-64d570953986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 백지타이핑 연습용\n",
    "# import numpy as np\n",
    "# arr1=np.array([1,2,3,4]).reshape(-1,1)\n",
    "# arr2=np.array([1,2,3,4]).reshape(-1,1)\n",
    "# arr3=np.array([1,2,3,4]).reshape(-1,1)\n",
    "\n",
    "# arr=np.array([arr1,arr2,arr3])\n",
    "# print(arr)\n",
    "# print(arr.shape)\n",
    "# np.mean([arr1,arr2,arr3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "81468dcd-5b38-42f4-a51c-88e6c184c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 백지타이핑 연습용\n",
    "# yellow=np.zeros(shape=(X_train.shape[0] ,1))\n",
    "# green=np.zeros(shape=(X_test.shape[0] ,5))\n",
    "# print(yellow.shape, green.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc67dfb6-4703-4309-88af-0d9742d1aab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f697abcc-96f1-4978-88d2-b008036f9895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9823578-3b53-428a-a135-25b7b4c95620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4205a767-691a-4986-b323-bf5dcb8a18c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2560864-ce49-4537-b839-2eae43e38d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5822682b-d7de-48b9-9eeb-cb592c78238c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d935fb5f-bf3f-4dbf-938f-f0114136fc32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb949dc4-311f-4575-8227-44f56ac4ce81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c438cf0-e5e7-47d7-bab8-4a8325c8ce8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec37b48e-9496-460a-8abb-26dc461b4da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03546131-600b-42e9-a488-6ba5938df6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6f8dbd-3626-461f-a04f-f7b700e89c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b27f6f0-c754-4e30-ab76-0471babcb7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa5c79a-858b-4104-a245-1c65609f07c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d9cfba-4837-496d-8b7b-97a29beb5833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bc50d0-bffe-4e3e-8432-0615b06df142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0db022-78d4-4a54-b88b-fada8bf70f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a2eb10-8cef-48da-afbf-b9deaee80eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2eacbf-500a-498d-ab1b-7ab58c73d357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00679b6-87ca-4a1e-b5d7-60453b6afc27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e1ba49-39dc-4482-bd3a-9beb56be51eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042f8e70-dd67-4d6e-a4dd-865cb640c65a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f6854e-733f-4393-bc1c-14ddc0f31f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9532627d-05f0-4480-a2f3-66633b33e079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef5b845-e584-4765-ad64-78a6f4248778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e783e5da-5824-419e-a439-8593972cd409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf8c92ab-572f-4f8e-952a-87393f19e7ef",
   "metadata": {},
   "source": [
    "# PipeLine  \n",
    "->연습용으로 titanic 불러옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b77c4-1031-4f76-b787-39af5da47ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c013558-0123-48ce-b087-ea2516a79f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler 문법 이런 거 생각 안 나면 걍 이거 해라\n",
    "# 사실 스케일링 얘는 안 해도 되는데 그냥 연습용 ^^\n",
    "\n",
    "\n",
    "pipe= Pipeline([     ('scaling',StandardScaler()), ('model', DecisionTreeClassifier())      ])\n",
    "pipe.fit(X_train, y_train)\n",
    "pred=model.predict(X_test)\n",
    "\n",
    "acc=accuracy_score(y_test, pred)\n",
    "f1=f1_score(y_test, pred, average='macro')\n",
    "print(f\"accuracy: {acc:.4f}  f1: {f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b5308f-e80c-4cdd-9e9b-dd5a2dea903b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c978e96-754a-42fc-b6e5-a29b9d40be1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a2797f-20fb-4b35-9b7e-e4748a57d72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fac626-6574-43a8-8cbc-1c693b70d15d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
